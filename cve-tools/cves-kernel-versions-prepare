#!/usr/bin/python3

from __future__ import print_function

import sys
import os
import json
from datetime import timedelta
import lazr
from debian.debian_support import Version

from ktl.launchpad_cache import LaunchpadCache


def archive_decode(archive):
    if archive == 'ubuntu':
        return (archive, [
            ('Release', 'release'),
            ('Security', 'security'),
            ('Updates', 'updates'),
            ('Proposed', 'proposed'),
        ])

    elif archive.startswith('ppa:'):
        return (archive, [('Release', 'ppa')])

    elif archive.find('-ppa:') >= 0:
        (to, archive) = archive.split('-', 1)
        mapping = archive_decode(archive)
        if mapping:
            pockets = []
            for pocket in to.split('/'):
                pockets.append(('Release', pocket.lower()))
            mapping = (mapping[0], pockets)
        return mapping

    return None

(creds, config, state) = sys.argv[1:4]
cache = os.path.join(state, "cache")
history = {}
if os.path.exists(cache):
    with open(cache) as cfd:
        history = json.load(cfd)

lp = LaunchpadCache.login_application('cves-kernel-versions', 'production')

ubuntu = lp.distributions['ubuntu']

with open(config, 'r') as cfd:
    for line in cfd:
        sys.stdout.flush()

        # Decode this entry.
        a = line.split()
        (series_name, source_name, _, _, flags) = a[0:5]
        flags_match = ',' + flags + ','

        #if series_name in ('upstream', 'product'):
        #    continue
        if ',tags-lp,' not in flags_match:
            continue

        flags = flags.split(',')

        archive_names = [ 'ubuntu', 'ppa:canonical-kernel-team/ubuntu/ppa' ]
        for flag in flags:
            if flag.startswith('archives:'):
                archive_names = flag[9:].split('|')

        archives = []
        for archive in archive_names:
            archive_map = archive_decode(archive)
            if not archive_map:
                print(f"BAD ARCHIVE {archive}: invalid archive")
            archives.append(archive_map)

        # Handle series variants.
        series_file = series_name.replace('/', '@')
        if 'esm-infra/' in series_name:
            series_name = series_name.split('/')[1]
        elif 'fips-updates/' in series_name:
            series_name = series_name.split('/')[1]
        else:
            series_name = series_name.split('/')[0]

        print("*** " + series_name + " " + source_name + " rescan ...", file=sys.stdout)

        # Look the package up in the various archives.
        try:
            series = ubuntu.getSeries(name_or_version=series_name)
        except lazr.restfulclient.errors.NotFound:
            print("NOT UBUNTU SERIES", archive_name)
            continue
        for archive in archives:
            if archive is None:
                print("NULL ARCHIVE", archive_name)
                continue
            (archive_name, mapping) = archive
            archive = lp.archives.getByReference(reference=archive_name)
            if not archive:
                print("BAD ARCHIVE", archive_name)
                sys.exit(1)

            current = history.setdefault(archive_name + ' ' + series_name + ' ' + source_name,
                {
                    'anchor_date': None,
                    'pocket_versions': {},
                    'pocket_version': {},
                }
            )

            anchor_date = current['anchor_date']
            anchor = None
            anchor_first = None
            new = []
            # We want to process the publications oldest to newest but the only
            # incremental interface gives us them in the opposite order.
            for pub in archive.getPublishedSources(source_name=source_name, distro_series=series, exact_match=True, order_by_date=True, created_since_date=anchor_date):
                ##print(pub, pub.pocket, pub.date_created, pub.status, pub.source_package_version)
                # Find the oldest record which may change, record its creation time as search anchor.
                if not anchor_first:
                    anchor_first = str(pub.date_created - timedelta(seconds=1))
                if pub.status in ('Published', 'Pending') and (pub.pocket != 'Release' or not anchor):
                    anchor = str(pub.date_created - timedelta(seconds=1))
                new.append(pub)
            if not anchor:
                anchor = anchor_first
            current['anchor_date'] = anchor

            new.reverse()
            for pub in new:
                # Record any potentially new versions for insertion into the versions list.
                pocket_versions = current['pocket_versions'].setdefault(pub.pocket, [])
                if pub.date_published:
                    rec = [str(pub.date_published), pub.source_package_version]
                    if rec not in pocket_versions:
                        print("New Version:", pub.source_package_version, pub.date_published, pub.pocket)
                        pocket_versions.append(rec)

                # Record the latest publications into each pocket.
                if pub.status == 'Published':
                    current['pocket_version'][pub.pocket] = pub.source_package_version
                elif pub.status == 'Deleted':
                    current['pocket_version'][pub.pocket] = None
                # Intuit the Release pocket where empty.
                if 'Release' not in current['pocket_version']:
                    if pub.pocket == 'Updates':
                        print("Intuiting Release Version:", pub.source_package_version, pub.date_published)
                        current['pocket_version']['Release'] = pub.source_package_version

        # Generate the archive overlayed views.
        pockets = {
            'release': None,
            'security': None,
            'updates': None,
            'proposed': None,
            'ppa': None,
        }
        versions_all = []
        archive_n = 0
        for archive in archives:
            if archive is None:
                print("NULL ARCHIVE", archive_name)
                continue
            (archive_name, mapping) = archive
            archive_n += 1

            current = history[archive_name + ' ' + series_name + ' ' + source_name]
            for (map_from, map_to) in mapping:
                version = current['pocket_version'].get(map_from, None)
                if version:
                    pockets[map_to] = version

            # If this is a PPA only mapping, we really only care about the last
            # latest version.  The history is not real.
            for (map_from, map_to) in mapping:
                # Proposed and PPAs are special we do not want to pollute the version
                # list with all our errors.  Just take the latest version in the source.
                # Also only keep the version if it is newer than everything we have
                # already.
                if map_to in ('proposed', 'ppa'):
                    if map_from in current['pocket_versions']:
                        try:
                            possible_version = current['pocket_versions'][map_from][-1][1]
                            possible_loose = Version(possible_version)
                            for existing in versions_all:
                                ##print(possible_version, existing)
                                if Version(existing) >= possible_loose:
                                    possible_version = None
                                    break
                            if possible_version:
                                versions_all += [ possible_version ]
                        except IndexError:
                            pass

                elif map_from in current['pocket_versions']:
                    versions_all += [ v for (t,v) in current['pocket_versions'][map_from] ]

        # Produce an order and version unique list.
        versions = []
        versions_all.sort(key=Version)
        for version in versions_all:
            if version not in versions:
                versions.append(version)

        # Generate the various output forms we use within the cve-autotriager.
        print("*** " + series_name + " " + source_name + " cve-pockets ...", file=sys.stdout)
        print("{release} {security} {updates} {proposed} {ppa}".format(**pockets), file=sys.stdout)
        pockets_file = os.path.join(state, series_file + '_' + source_name + '_cve-pockets')
        with open(pockets_file, 'w') as pfd:
            print("{release} {security} {updates} {proposed} {ppa}".format(**pockets), file=pfd)
        print("*** " + series_name + " " + source_name + " tags ...", file=sys.stdout)
        tags_file = os.path.join(state, series_file + '_' + source_name + '_tags')
        with open(tags_file, 'w') as tfd:
            print("\n".join(versions), file=tfd)

with open(cache + '.new', 'w') as cfd:
    json.dump(history, cfd, indent=2)
os.rename(cache + '.new', cache)
